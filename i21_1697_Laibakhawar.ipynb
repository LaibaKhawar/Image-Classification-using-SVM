{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request made from IP: 192.168.1.1\n",
      "Request made from IP: 192.168.1.2\n",
      "Request made from IP: 192.168.1.3\n",
      "Request made from IP: 192.168.1.4\n",
      "Request made from IP: 192.168.1.5\n",
      "Request made from IP: 192.168.1.1\n",
      "Request made from IP: 192.168.1.2\n",
      "Request made from IP: 192.168.1.3\n",
      "Request made from IP: 192.168.1.4\n",
      "Request made from IP: 192.168.1.5\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from collections import deque\n",
    "from random import choice\n",
    "IP_POOL = ['192.168.1.1', '192.168.1.2', '192.168.1.3', '192.168.1.4', '192.168.1.5'] ##ip's for rotation\n",
    "\n",
    "#helper function to simulate making an HTTP request \n",
    "def simulate_http_request(ip):\n",
    "    print(f\"Request made from IP: {ip}\")\n",
    "\n",
    "#class for throttling mechanism (to be implemented) \n",
    "class Throttler:\n",
    "    def __init__(self, rate_limit):\n",
    "        self.requests = deque()  \n",
    "        self.rate_limit = rate_limit \n",
    "\n",
    "    def allow_request(self):\n",
    "        current_time = time.time()\n",
    "        # if more than 1 min old\n",
    "        while self.requests and current_time - self.requests[0] > 60:\n",
    "            self.requests.popleft()\n",
    "        \n",
    "        # if new request more than rate limit\n",
    "        if len(self.requests) < self.rate_limit:\n",
    "            self.requests.append(current_time)\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "##function to be implemented\n",
    "def make_requests(n):\n",
    "    \"\"\" \n",
    "    Implement this function to make `n` requests to the server using IP rotation and a custom throttling \n",
    "    mechanism. \n",
    "\n",
    "    Args: - n (int): Number of requests to make. \n",
    "    Rotate through the IP_POOL list for each request and ensure requests are throttled to no more than 5 \n",
    "    requests per minute. \n",
    "    Use the `simulate_http_request` function to make a request, selecting the next available IP from \n",
    "    `IP_POOL` in a round-robin manner. \n",
    "    \"\"\" \n",
    "    throttler = Throttler(5) \n",
    "    ip_index = 0\n",
    "    \n",
    "    for _ in range(n):\n",
    "        if ip_index >= len(IP_POOL):\n",
    "            ip_index = 0\n",
    "        ip = IP_POOL[ip_index]\n",
    "        ip_index += 1\n",
    "\n",
    "        while not throttler.allow_request():\n",
    "            time.sleep(1)  # Wait a bit if the rate limit is hit\n",
    "            \n",
    "        # Make request\n",
    "        simulate_http_request(ip)\n",
    "\n",
    "make_requests(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4925\n"
     ]
    }
   ],
   "source": [
    "def load_images_from_folder(folder, max_images_per_class=1000):\n",
    "    # changed the code a bit to have a limit on \n",
    "    # max images we are reading per class as\n",
    "    # currently its very computationally expensive\n",
    "    # to train SVM on full 25000 images\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_count = {'cat': 0, 'dog': 0}  # Dictionary to track the count of each class\n",
    "\n",
    "    for filename in os.listdir(folder):\n",
    "        current_class = 'cat' if 'cat' in filename else 'dog'\n",
    "        if class_count[current_class] >= max_images_per_class:\n",
    "            continue\n",
    "        img = imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            # Consider handling label transformation within the training\n",
    "            # and evaluation functions if necessary (typically, SVM labels are -1 and 1)\n",
    "            # so we are transforming labels to -1 for cat and 1 for dog\n",
    "            labels.append(-1 if 'cat' in filename else 1)\n",
    "            class_count[current_class] += 1\n",
    "    return images, labels\n",
    "\n",
    "def preprocess_images(images, target_size=(64, 64)): \n",
    "    \"\"\" \n",
    "    Resize images and flatten them for SVM processing. \n",
    "     \n",
    "    Args: \n",
    "    - images (list of ndarray): List of images. \n",
    "    - target_size (tuple of int): Size to which images will be resized. \n",
    " \n",
    "    Returns: \n",
    "    - np.array: Array of reshaped images. \n",
    "    \"\"\" \n",
    "    processed_images = [] \n",
    "    for img in images: \n",
    "        img_resized = resize(img, target_size, anti_aliasing=True, mode='reflect') \n",
    "        processed_images.append(img_resized.flatten()) \n",
    "    return np.array(processed_images)\n",
    "\n",
    "# training on 2 epochs only in interest of time\n",
    "def train_svm(features, labels, epochs=10, learning_rate=0.01, lambda_param=0.01): \n",
    "    \"\"\" \n",
    "    Train a linear SVM classifier from scratch. \n",
    "     \n",
    "    Args: \n",
    "    - features (np.array): Feature array of image data. \n",
    "    - labels (list of int): List of labels corresponding to the images. \n",
    "    - epochs (int): Number of epochs to train. \n",
    "    - learning_rate (float): Learning rate for the gradient descent. \n",
    "    - lambda_param (float): Regularization parameter. \n",
    " \n",
    "    Returns: \n",
    "    - np.array: Weight vector after training. \n",
    "    \"\"\" \n",
    "    weights = np.zeros(features.shape[1])\n",
    "    for epoch in range(epochs):\n",
    "        for i, feature in enumerate(features):\n",
    "            condition = labels[i] * np.dot(weights, feature)\n",
    "            if condition < 1:\n",
    "                # if incorrect prediction update weights\n",
    "                weights -= learning_rate * ((2 * lambda_param * weights) - labels[i] * feature)\n",
    "            else:\n",
    "                # or if Correct prediction then just apply regularization\n",
    "                weights -= learning_rate * (2 * lambda_param * weights)\n",
    "    return weights\n",
    "\n",
    "def evaluate_svm(weights, features, labels): \n",
    "    \"\"\" \n",
    "    Evaluate the trained SVM on a test set. \n",
    "     \n",
    "    Args: \n",
    "    - weights (np.array): The weights of the trained SVM. \n",
    "    - features (np.array): Feature array of image data for testing. \n",
    "    - labels (list of int): List of labels corresponding to the test images. \n",
    " \n",
    "    Returns: \n",
    "    - float: Accuracy of the classifier on the test set. \n",
    "    \"\"\" \n",
    "    predictions = np.sign(np.dot(features, weights))\n",
    "    accuracy = np.mean(predictions == labels)\n",
    "    return accuracy\n",
    "\n",
    "##load and preprocess images \n",
    "folder = 'tempimage' # i have pasted 1127 images of cat and 1103 images of dogs in tempimages folder and using that folder im working \n",
    "images, labels = load_images_from_folder(folder) \n",
    "processed_images = preprocess_images(images) \n",
    "\n",
    "##split data into training and testing sets \n",
    "features_train, features_test, labels_train, labels_test = train_test_split( \n",
    "    processed_images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "weights = train_svm(features_train, labels_train) \n",
    "accuracy = evaluate_svm(weights, features_test, labels_test)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this we can say that instead of just taking pixel values of image you can use image features such as SIFT, SURF, edge and corner detectors or some modern img feature techniques from CNNs etc. Along witht this we can change the SVM kernel to a higher dimensional space if data isn't linearly separable in low dimension"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
